{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d94d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_data\u001b[39m(df):\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[32m      7\u001b[39m     X = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['class'])\n",
    "    y = df['class']\n",
    "\n",
    "    # Split into train/test first (important to avoid leakage)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Handle class imbalance ONLY on training data\n",
    "    print(\"Original class distribution in train:\", y_train.value_counts())\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Resampled class distribution in train:\", y_train_resampled.value_counts())\n",
    "\n",
    "    # Numerical columns to scale (example: adjust to your dataset)\n",
    "    numeric_cols = ['purchase_value', 'age', 'time_since_signup', 'time_diff_seconds']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_resampled[numeric_cols] = scaler.fit_transform(X_train_resampled[numeric_cols])\n",
    "    X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # Categorical columns to encode\n",
    "    categorical_cols = ['source', 'browser', 'sex']\n",
    "\n",
    "    # One-hot encode training and test categorical features\n",
    "    X_train_encoded = pd.get_dummies(X_train_resampled, columns=categorical_cols, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Align columns of train and test (some categories might be missing in test)\n",
    "    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "    return X_train_encoded, X_test_encoded, y_train_resampled, y_test\n",
    "\n",
    "# Example usage after feature engineering:\n",
    "# X_train, X_test, y_train, y_test = preprocess_data(fraud_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b87b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
